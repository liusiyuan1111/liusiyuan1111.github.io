<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>论文翻译：Deep Image Retrieval  A Survey | 刘思远的博客</title><meta name="keywords" content="论文翻译,图像检索,深度学习,Paper,CV"><meta name="author" content="Liu"><meta name="copyright" content="Liu"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Deep Image Retrieval: A Survey深度图像检索综述 Abstract—In recent years a vast amount of visual content has been generated and shared from various fields, such as social media platforms, medical images, and r">
<meta property="og:type" content="article">
<meta property="og:title" content="论文翻译：Deep Image Retrieval  A Survey">
<meta property="og:url" content="http://example.com/2021/02/05/07-%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91%EF%BC%9ADeep-Image-Retrieval-A-Survey/index.html">
<meta property="og:site_name" content="刘思远的博客">
<meta property="og:description" content="Deep Image Retrieval: A Survey深度图像检索综述 Abstract—In recent years a vast amount of visual content has been generated and shared from various fields, such as social media platforms, medical images, and r">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg">
<meta property="article:published_time" content="2021-02-05T11:53:38.000Z">
<meta property="article:modified_time" content="2021-05-23T11:17:16.610Z">
<meta property="article:author" content="Liu">
<meta property="article:tag" content="论文翻译">
<meta property="article:tag" content="图像检索">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="Paper">
<meta property="article:tag" content="CV">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://example.com/2021/02/05/07-%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91%EF%BC%9ADeep-Image-Retrieval-A-Survey/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '论文翻译：Deep Image Retrieval  A Survey',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2021-05-23 19:17:16'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">10</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">30</div></a></div></div></div><hr/></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">刘思远的博客</a></span><div id="menus"><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">论文翻译：Deep Image Retrieval  A Survey</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-02-05T11:53:38.000Z" title="发表于 2021-02-05 19:53:38">2021-02-05</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-05-23T11:17:16.610Z" title="更新于 2021-05-23 19:17:16">2021-05-23</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="论文翻译：Deep Image Retrieval  A Survey"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="Deep-Image-Retrieval-A-Survey"><a href="#Deep-Image-Retrieval-A-Survey" class="headerlink" title="Deep Image Retrieval: A Survey"></a>Deep Image Retrieval: A Survey</h1><p>深度图像检索综述</p>
<p><strong>Abstract</strong>—In recent years a vast amount of visual content has been generated and shared from various fields, such as social media platforms, medical images, and robotics. This abundance of content creation and sharing has introduced new challenges. In particular, searching databases for similar content, i.e., content based image retrieval (CBIR), is a long-established research area, and more efficient and accurate methods are needed for real time retrieval. Artificial intelligence has made progress in CBIR and has significantly facilitated the process of intelligent search. In this survey we organize and review recent CBIR works that are developed based on deep learning algorithms and techniques, including insights and techniques from recent papers. We identify and present the commonly-used benchmarks and evaluation methods used in the field. We collect common challenges and propose promising future directions. More specifically, we focus on image retrieval with deep learning and organize the state of the art methods according to the types of deep network structure, deep features, feature enhancement methods, and network fine-tuning strategies. Our survey considers a wide variety of recent methods, aiming to promote a global view of the field of instance-based CBIR.<br><strong>Index Terms</strong>—Content based image retrieval, Deep learning, Convolutional neural networks, Literature survey</p>
<p><strong>摘要</strong>—近年来，从社交媒体平台、医学图像和机器人技术等各个领域产生并共享了大量视觉内容。这种丰富的内容创建和共享带来了新的挑战。特别是，在数据库中搜索相似的内容，即基于内容的图像检索(CBIR)，是一个由来已久的研究领域，实时检索需要更有效和更准确的方法。人工智能在CBIR取得了进展，极大地促进了智能搜索的进程。在这篇综述中，我们组织和回顾了CBIR最近的工作，这些工作是基于深度学习算法和技术开发的，包括来自最近论文的算法和技术。我们确定并介绍了该领域常用的基准和评估方法。我们收集共同的挑战，并提出有前景的未来研究方向。更具体地说，我们关注具有深度学习的图像检索，并根据深度网络结构、深度特征、特征增强方法和网络微调策略的类型来组织最先进的方法。我们的综述考虑了各种各样的最新方法，旨在促进基于实例的CBIR领域的全球视野。</p>
<p><strong>索引</strong>—基于内容的图像检索、深度学习、卷积神经网络、文献综述</p>
<h2 id="1-INTRODUCTION"><a href="#1-INTRODUCTION" class="headerlink" title="1 INTRODUCTION"></a><strong>1 INTRODUCTION</strong></h2><h2 id="1-引言"><a href="#1-引言" class="headerlink" title="1 引言"></a><strong>1 引言</strong></h2><p>CONTENT based image retrieval (CBIR) is the problem of searching for semantically matched or similar images in a large image gallery by analyzing their visual content, given a query image that describes the user’s needs. CBIR has been a longstanding research topic in the computer vision and multi-media community [1], [2]. With the present, exponentially increasing, amount of image and video data, the development of appropriate information systems that efficiently manage such large image collections is of utmost importance, with image searching being one of the most indispensable techniques. Thus there is nearly endless potential for applications of CBIR, such as person re-identification [3], remote sensing [4], medical image search [5], and shopping recommendation in online markets [6], among many others.</p>
<p>基于内容的图像检索(CBIR)是通过分析图像的视觉内容，在大型图像库中搜索语义匹配或相似的图像的问题，给出描述用户需求的查询图像。CBIR一直是计算机视觉和多媒体领域的一个长期研究课题。随着当前图像和视频数据量的指数级增长，开发能够有效管理如此大的图像集合的信息系统是至关重要的，其中图像检索是不可缺少的技术之一。因此，CBIR的应用潜力几乎是无穷无尽的，如行人重识别，遥感图像，医学图像检索，以及在线商城的购物推荐等等。</p>
<p>A broad categorization of CBIR methodologies depends on the level of retrieval, i.e., instance level and category level. In instance level image retrieval, a query image of a particular object or scene (e.g., the Eiffel Tower) is given and the goal is to find images containing the same object or scene that may be captured under different conditions [7], [8]. In contrast, the goal of category level retrieval is to find images of the same class as the query (e.g., dogs, cars, etc.). Instance level retrieval is more challenging and promising as it satisfies specific objectives for many applications. Notice that we limit the focus of this survey to instance-level image retrieval and in the following, if not further specified, “image retrieval” and “instance retrieval” are considered equivalent and will be used interchangeably. </p>
<p>CBIR方法的广泛分类取决于检索的级别，即实例级和类别级。在实例级图像检索中，给出特定对象或场景(例如，埃菲尔铁塔)的查询图像，并且目标是找到包含在不同条件下可能被捕获的相同对象或场景的图像。相比之下，类别级检索的目标是找到与查询相同类别的图像(例如，狗、汽车等))。实例级检索更具挑战性和前景，因为它满足了许多应用程序的特定目标。注意我们将本次综述的重点限于实例级图像检索，在下文中，如果没有进一步说明，“图像检索”和“实例检索”被认为是等效的，将可互换使用。</p>
<p>Finding a desired image can require a search among thousands, millions, or even billions of images. Hence, searching efficiently is as critical as searching accurately, to which continued efforts have been devoted [7], [8], [9], [10], [11].To enable accurate and efficient retrieval of massive image collections,compact yet rich feature representations are at the core of CBIR.</p>
<p>找到想要的图像可能需要在数千、数百万甚至数十亿张图像中进行搜索。因此，有效的搜索和精确的搜索一样重要，对此人们一直在努力，参考文献7-11。为了准确高效地检索大量图像集合，紧凑而丰富的特征表示是CBIR的核心。</p>
<p>In the past two decades, remarkable progress has been made in image feature representations, which mainly consist of two important periods: feature engineering and feature learning (particularly deep learning). In the feature engineering era (i.e., pre-deep learning), the field was dominated by milestone hand-engineered feature descriptors, such as the Scale-Invariant Feature Transform (SIFT) [19]. The feature learning stage, the deep learning era since 2012, begins with artificial neural networks, particularly the breakthrough ImageNet and the Deep Convolutional Neural Network (DCNN) AlexNet [20]. Since then, deep learning has impacted a broad range of research areas, since DCNNs can learn powerful feature representations with multiple levels of abstraction directly from data. Deep learning techniques have attracted enormous attention and have brought about considerable breakthroughs in many computer vision tasks, including image classification [20], [21], [22], object detection [23], and image retrieval [10], [13], [14].</p>
<p>在过去的二十年里，图像特征表示取得了显著的进展，主要包括两个重要阶段:特征工程和特征学习(特别是深度学习)。在特征工程时代(即深度学习前)，该领域由里程碑式的手工工程特征描述符主导，如尺度不变特征变换(SIFT) 。特征学习阶段，自2012年以来的深度学习时代，始于人工神经网络，特别是突破性的ImageNet和深度卷积神经网络(DCNN) AlexNet  。从那以后，深度学习影响了广泛的研究领域，因为数据挖掘神经网络可以直接从数据中学习具有多层次抽象的强大特征表示。深度学习技术已经引起了极大的关注，并在许多计算机视觉任务中带来了相当大的突破，包括图像分类、对象检测和图像检索。</p>
<p>Excellent surveys for traditional image retrieval can be found in [1], [2], [8]. This paper, in contrast, focuses on deep learning based methods. A comparison of our work with other published surveys [8], [14], [15], [16] is shown in Table 1. Deep learning for image retrieval is comprised of the essential stages shown in Figure 1 and various methods, focusing on one or more stages, have been proposed to improve retrieval accuracy and efficiency. In this survey, we include comprehensive details about these methods, including feature fusion methods and network fine-tuning strategies etc. , motivated by the following questions that have been driving research in this domain:</p>
<p>传统图像检索的方法可以在综述[1]、[2]、[8]中找到。相比之下，本文侧重于基于深度学习的方法。我们的工作与其他已发表的综述[8]、[14]、[15]、[16]的比较见表1。图像检索的深度学习由图1所示的基本阶段组成，并且已经提出了各种方法，集中在一个或多个阶段，以提高检索的准确性和效率。在本篇综述中，包括了这些方法的综合细节，特征融合方法和网络微调策略等，其动机是推动该领域研究的以下问题:</p>
<ol>
<li>By using off-the-shelf models only, how do deep features outperform hand-crafted features?</li>
<li>In case of domain shifts across training datasets, how can we adapt off-the-shelf models to maintain or even improve<br>retrieval performance?</li>
<li>Since deep features are generally high-dimensional, how can we effectively utilize them to perform efficient image<br>retrieval, especially for large-scale datasets?</li>
</ol>
<p>1)仅使用现成的模型，深度特征如何胜过手工制作的特征？</p>
<p>2)在跨训练数据集的领域转移的情况下，我们如何适应现成的模型来保持甚至提高检索性能？</p>
<p>3)由于深度特征通常是高维的，我们如何有效地利用它们来执行高效的图像检索，尤其是对于大规模数据集。</p>
<p>TABLE 1: A summary and comparison of the primary surveys in the field of image retrieval.</p>
<p>表1:图像检索领域主要综述文献的总结和比较。</p>
<p><img src="https://i.loli.net/2021/02/05/bM8DLriRHAEPGvU.png" alt="image-20210205203313875"></p>
<p><img src="https://i.loli.net/2021/02/05/U36pBOD87Ckujrd.png" alt="image-20210205203545671"></p>
<p>Fig. 1: In deep image retrieval, feature embedding and aggregation methods are used to enhance the discrimination of deep features. Similarity is measured on these enhanced features using Euclidean or Hamming distances.</p>
<p>图1:在深度图像检索中，使用特征嵌入和聚集方法来增强深度特征的区分度。使用欧几里德距离或汉明距离来测量这些增强特征的相似性。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Liu</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2021/02/05/07-%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91%EF%BC%9ADeep-Image-Retrieval-A-Survey/">http://example.com/2021/02/05/07-%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91%EF%BC%9ADeep-Image-Retrieval-A-Survey/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">刘思远的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/">论文翻译</a><a class="post-meta__tags" href="/tags/%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2/">图像检索</a><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><a class="post-meta__tags" href="/tags/Paper/">Paper</a><a class="post-meta__tags" href="/tags/CV/">CV</a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/05/14/08-%E5%AA%92%E4%BD%93%E6%9F%A5%E8%AF%A2+rem%E5%B8%83%E5%B1%80/"><img class="prev-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">媒体查询+rem布局</div></div></a></div><div class="next-post pull-right"><a href="/2021/01/17/06-win10-Linux-manjaro-%E5%8F%8C%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85/"><img class="next-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">win10+Linux(manjaro)双系统安装</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2021/05/23/09-Transformer%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E8%AE%BA%E6%96%87/" title="Transformer图像分割论文"><img class="cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-05-23</div><div class="title">Transformer图像分割论文</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Liu</div><div class="author-info__description">人生苦短，我学Python</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">10</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">30</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Deep-Image-Retrieval-A-Survey"><span class="toc-number">1.</span> <span class="toc-text">Deep Image Retrieval: A Survey</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-INTRODUCTION"><span class="toc-number">1.1.</span> <span class="toc-text">1 INTRODUCTION</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E5%BC%95%E8%A8%80"><span class="toc-number">1.2.</span> <span class="toc-text">1 引言</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2021/09/24/10-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E5%A4%84%E7%90%86%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/" title="数据分析与处理开发环境搭建"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="数据分析与处理开发环境搭建"/></a><div class="content"><a class="title" href="/2021/09/24/10-%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B8%8E%E5%A4%84%E7%90%86%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/" title="数据分析与处理开发环境搭建">数据分析与处理开发环境搭建</a><time datetime="2021-09-24T02:29:53.000Z" title="发表于 2021-09-24 10:29:53">2021-09-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/05/23/09-Transformer%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E8%AE%BA%E6%96%87/" title="Transformer图像分割论文"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Transformer图像分割论文"/></a><div class="content"><a class="title" href="/2021/05/23/09-Transformer%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E8%AE%BA%E6%96%87/" title="Transformer图像分割论文">Transformer图像分割论文</a><time datetime="2021-05-23T15:29:53.000Z" title="发表于 2021-05-23 23:29:53">2021-05-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/05/14/08-%E5%AA%92%E4%BD%93%E6%9F%A5%E8%AF%A2+rem%E5%B8%83%E5%B1%80/" title="媒体查询+rem布局"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="媒体查询+rem布局"/></a><div class="content"><a class="title" href="/2021/05/14/08-%E5%AA%92%E4%BD%93%E6%9F%A5%E8%AF%A2+rem%E5%B8%83%E5%B1%80/" title="媒体查询+rem布局">媒体查询+rem布局</a><time datetime="2021-05-14T05:25:53.000Z" title="发表于 2021-05-14 13:25:53">2021-05-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/02/05/07-%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91%EF%BC%9ADeep-Image-Retrieval-A-Survey/" title="论文翻译：Deep Image Retrieval  A Survey"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="论文翻译：Deep Image Retrieval  A Survey"/></a><div class="content"><a class="title" href="/2021/02/05/07-%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91%EF%BC%9ADeep-Image-Retrieval-A-Survey/" title="论文翻译：Deep Image Retrieval  A Survey">论文翻译：Deep Image Retrieval  A Survey</a><time datetime="2021-02-05T11:53:38.000Z" title="发表于 2021-02-05 19:53:38">2021-02-05</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/01/17/06-win10-Linux-manjaro-%E5%8F%8C%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85/" title="win10+Linux(manjaro)双系统安装"><img src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="win10+Linux(manjaro)双系统安装"/></a><div class="content"><a class="title" href="/2021/01/17/06-win10-Linux-manjaro-%E5%8F%8C%E7%B3%BB%E7%BB%9F%E5%AE%89%E8%A3%85/" title="win10+Linux(manjaro)双系统安装">win10+Linux(manjaro)双系统安装</a><time datetime="2021-01-17T11:05:35.000Z" title="发表于 2021-01-17 19:05:35">2021-01-17</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By Liu</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>